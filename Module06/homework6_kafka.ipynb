{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e34c4975-744a-45cd-9608-9d779457e972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import time \n",
    "\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "def json_serializer(data):\n",
    "    return json.dumps(data).encode('utf-8')\n",
    "\n",
    "server = 'localhost:9092'\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=[server],\n",
    "    value_serializer=json_serializer\n",
    ")\n",
    "\n",
    "producer.bootstrap_connected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "465adc8d-fda0-42a5-832e-c2c979137040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: {'number': 0}\n",
      "Sent: {'number': 1}\n",
      "Sent: {'number': 2}\n",
      "Sent: {'number': 3}\n",
      "Sent: {'number': 4}\n",
      "Sent: {'number': 5}\n",
      "Sent: {'number': 6}\n",
      "Sent: {'number': 7}\n",
      "Sent: {'number': 8}\n",
      "Sent: {'number': 9}\n",
      "took 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "topic_name = 'test-topic'\n",
    "\n",
    "for i in range(10):\n",
    "    message = {'number': i}\n",
    "    producer.send(topic_name, value=message)\n",
    "    print(f\"Sent: {message}\")\n",
    "    #time.sleep(0.05)\n",
    "\n",
    "#producer.flush()\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'took {(t1 - t0):.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44171b0a-e7f0-4799-8c9c-aa429987a708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "topic_name = 'test-topic'\n",
    "\n",
    "producer.flush()\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'took {(t1 - t0):.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e67f483-57a0-4f78-8166-b34392ea3225",
   "metadata": {},
   "source": [
    "Read the data\n",
    "\n",
    "Data folder and file: Module06/green_tripdata_2019-10.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42e51f15-19c1-443a-8414-9fdcfff46491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3649591-f3f8-452c-8453-90cd4f9578ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16682/3924064876.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('Module06/green_tripdata_2019-10.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 476386 entries, 0 to 476385\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   VendorID               387007 non-null  float64\n",
      " 1   lpep_pickup_datetime   476386 non-null  object \n",
      " 2   lpep_dropoff_datetime  476386 non-null  object \n",
      " 3   store_and_fwd_flag     387007 non-null  object \n",
      " 4   RatecodeID             387007 non-null  float64\n",
      " 5   PULocationID           476386 non-null  int64  \n",
      " 6   DOLocationID           476386 non-null  int64  \n",
      " 7   passenger_count        387007 non-null  float64\n",
      " 8   trip_distance          476386 non-null  float64\n",
      " 9   fare_amount            476386 non-null  float64\n",
      " 10  extra                  476386 non-null  float64\n",
      " 11  mta_tax                476386 non-null  float64\n",
      " 12  tip_amount             476386 non-null  float64\n",
      " 13  tolls_amount           476386 non-null  float64\n",
      " 14  ehail_fee              0 non-null       float64\n",
      " 15  improvement_surcharge  476386 non-null  float64\n",
      " 16  total_amount           476386 non-null  float64\n",
      " 17  payment_type           387007 non-null  float64\n",
      " 18  trip_type              387005 non-null  float64\n",
      " 19  congestion_surcharge   387007 non-null  float64\n",
      "dtypes: float64(15), int64(2), object(3)\n",
      "memory usage: 72.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Module06/green_tripdata_2019-10.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "348f8809-1e4e-48c2-94eb-0e721b7b74b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>tip_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-10-01 00:26:02</td>\n",
       "      <td>2019-10-01 00:39:58</td>\n",
       "      <td>112</td>\n",
       "      <td>196</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.88</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-10-01 00:18:11</td>\n",
       "      <td>2019-10-01 00:22:38</td>\n",
       "      <td>43</td>\n",
       "      <td>263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-10-01 00:09:31</td>\n",
       "      <td>2019-10-01 00:24:47</td>\n",
       "      <td>255</td>\n",
       "      <td>228</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-10-01 00:37:40</td>\n",
       "      <td>2019-10-01 00:41:49</td>\n",
       "      <td>181</td>\n",
       "      <td>181</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-10-01 00:08:13</td>\n",
       "      <td>2019-10-01 00:17:56</td>\n",
       "      <td>97</td>\n",
       "      <td>188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  lpep_pickup_datetime lpep_dropoff_datetime  PULocationID  DOLocationID  \\\n",
       "0  2019-10-01 00:26:02   2019-10-01 00:39:58           112           196   \n",
       "1  2019-10-01 00:18:11   2019-10-01 00:22:38            43           263   \n",
       "2  2019-10-01 00:09:31   2019-10-01 00:24:47           255           228   \n",
       "3  2019-10-01 00:37:40   2019-10-01 00:41:49           181           181   \n",
       "4  2019-10-01 00:08:13   2019-10-01 00:17:56            97           188   \n",
       "\n",
       "   passenger_count  trip_distance  tip_amount  \n",
       "0              1.0           5.88        0.00  \n",
       "1              1.0           0.80        0.00  \n",
       "2              2.0           7.50        0.00  \n",
       "3              1.0           0.90        0.00  \n",
       "4              1.0           2.52        2.26  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['lpep_pickup_datetime',\n",
    "'lpep_dropoff_datetime',\n",
    "'PULocationID',\n",
    "'DOLocationID',\n",
    "'passenger_count',\n",
    "'trip_distance',\n",
    "'tip_amount']]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec8268f6-b1aa-4594-a129-561c255f265f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(476386, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9603bd2f-ce38-4265-baef-b969ce21ae50",
   "metadata": {},
   "source": [
    "Now, we send the dataframe to a kafka topic. We create the topic `green-rides-201910` for this messages.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ec25af-b6e5-47be-bf41-81a131c1ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "topic_name = 'green-rides-201910'\n",
    "\n",
    "for row in df.itertuples(index=False):\n",
    "    row_dict = {col: getattr(row, col) for col in row._fields}\n",
    "    producer.send(topic_name, value=row_dict)\n",
    "    print(f\"Sent: {row_dict}\")\n",
    "\n",
    "producer.flush()\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'took {(t1 - t0):.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e65bf06-dd24-425a-b529-f6a6906282e9",
   "metadata": {},
   "source": [
    "## Creating a PySpark consumer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43889a96-2cbb-40bc-b6e8-d2de244c1695",
   "metadata": {},
   "source": [
    "Spark needs a library (jar) to be able to connect to Kafka, so we need to tell PySpark that it needs to use it:tOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a87bef-c391-4029-b453-5bbdcb0f7e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "pyspark_version = pyspark.__version__\n",
    "kafka_jar_package = f\"org.apache.spark:spark-sql-kafka-0-10_2.12:{pyspark_version}\"\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"GreenTripsConsumer\") \\\n",
    "    .config(\"spark.jars.packages\", kafka_jar_package) \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eea9548-80e8-4e2b-8e2f-5cb4f1d0c62b",
   "metadata": {},
   "source": [
    "Now we can connect to the stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d572326-fb62-4c4d-b56f-fcc6340ac815",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_stream = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"localhost:9092\") \\\n",
    "    .option(\"subscribe\", \"green-rides-201910\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce040b5-09a4-4f27-953d-a1f2c7f9df27",
   "metadata": {},
   "source": [
    "So we can execute a function over each mini-batch. Let's run take(1) there to see what do we have in the stream:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29546591-5647-4ea0-a8ba-dd3c70c9d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def peek(mini_batch, batch_id):\n",
    "    first_row = mini_batch.take(1)\n",
    "\n",
    "    if first_row:\n",
    "        print(first_row[0])\n",
    "\n",
    "query = green_stream.writeStream.foreachBatch(peek).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565ad910-a355-48dc-907d-7246f68b2891",
   "metadata": {},
   "source": [
    "Now let's stop the query, so it doesn't keep consuming messages from the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e355bc4-cde9-4e7d-9034-9834c8ea4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc298d45-e041-4c04-b4d3-66c67c7aef18",
   "metadata": {},
   "source": [
    "## Parsing the data\n",
    "\n",
    "The data is JSON, but currently it's in binary format. We need to parse it and turn it into a streaming dataframe with proper columns.\r\n",
    "\r\n",
    "Similarly to PySpark, we define the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7351b2-f636-4246-a3f5-fa1e0462cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types\n",
    "\n",
    "schema = types.StructType() \\\n",
    "    .add(\"lpep_pickup_datetime\", types.StringType()) \\\n",
    "    .add(\"lpep_dropoff_datetime\", types.StringType()) \\\n",
    "    .add(\"PULocationID\", types.IntegerType()) \\\n",
    "    .add(\"DOLocationID\", types.IntegerType()) \\\n",
    "    .add(\"passenger_count\", types.DoubleType()) \\\n",
    "    .add(\"trip_distance\", types.DoubleType()) \\\n",
    "    .add(\"tip_amount\", types.DoubleType())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab140e9-54ae-458c-bbba-426f82b5c1a7",
   "metadata": {},
   "source": [
    "And apply this schema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6691760b-ff64-4b22-a5f9-e1be13a11ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "green_stream = green_stream \\\n",
    "  .select(F.from_json(F.col(\"value\").cast('STRING'), schema).alias(\"data\")) \\\n",
    "  .select(\"data.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d054df-a990-49bf-b403-c60bdfe05cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_stream.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e198d15f-4f74-4483-8586-e4dbcb88b26e",
   "metadata": {},
   "source": [
    "## Most popular destination\n",
    "\n",
    "Now let's finally do some streaming analytics. We will see what's the most popular destination currently based on our stream of data (which ideally we should have sent with delays like we did in workshop 2)\n",
    "This is how you can do it:\n",
    "    1. \r\n",
    "Add a column \"timestamp\" using the current_timestamp functi\n",
    "    2. n\r\n",
    "Group b        - y:\r\n",
    "5 minutes window based on the timestamp column (F.window(col(\"timestamp\"), \"5 minutes        - \"))\r\n",
    "\"DOLocati\n",
    "    3. nID\"\r\n",
    "Order by\n",
    " count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd0195-73c6-4eaa-add2-c5731a8f7774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp, col, window, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f3c1f5-3e79-4b27-b2a8-83b2b1d49762",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_stream_with_timestamp = green_stream.withColumn(\"timestamp\", current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f43d1-7730-45da-b0e6-28df221f9826",
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_destinations = green_stream_with_timestamp \\\n",
    "    .groupBy(window(col(\"timestamp\"), \"5 minutes\"), col(\"DOLocationID\")) \\\n",
    "    .agg(count(\"*\").alias(\"count\")) \\\n",
    "    .orderBy(col(\"count\").desc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844e305a-36f1-4d36-b48f-4be252d170d5",
   "metadata": {},
   "source": [
    "You can print the output to the console using this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d41e8c-9dc7-450d-a16e-d4833ae9d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = popular_destinations \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"complete\") \\\n",
    "    .format(\"console\") \\\n",
    "    .option(\"truncate\", \"false\") \\\n",
    "    .start()\n",
    "\n",
    "query.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580fe6a-1cd4-45f5-bb72-e820508421e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
